'''
ë…¼ë¬¸(PDF)ë¥¼ ì—…ë¡œë“œí•˜ê³ , ë‚´ìš© ìš”ì•½ ë° ì§ˆì˜.
ë°ëª¨ í˜ì´ì§€.
'''
import os
import time
import tempfile
import streamlit as st
import google.generativeai as genai
from dotenv import load_dotenv

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="PDF ìš”ì•½ ë° Q&A ë´‡",
    page_icon="ğŸ“„",
    layout="wide"
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    api_key_env = os.getenv("GOOGLE_API_KEY")
    api_key = st.text_input("Google API Key", value=api_key_env if api_key_env else "", type="password")
    
    st.divider()
    
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])
    
    st.info("ğŸ’¡ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ Geminiì— ì „ì†¡ë˜ì–´ ì²˜ë¦¬ë©ë‹ˆë‹¤.")

# ë©”ì¸ í™”ë©´
st.title("ğŸ“„ ë¬¸ì„œ ìš”ì•½ ë° ëŒ€í™”í•˜ê¸°")

if not api_key:
    st.warning("Google API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.stop()

# API ì„¤ì •
genai.configure(api_key=api_key)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "gemini_file" not in st.session_state:
    st.session_state.gemini_file = None
if "summary" not in st.session_state:
    st.session_state.summary = None
if "last_uploaded_filename" not in st.session_state:
    st.session_state.last_uploaded_filename = None

def process_file(uploaded_file):
    """íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."""
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name

    with st.spinner(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘... ({uploaded_file.name})"):
        # íŒŒì¼ì„ Geminiì— ì—…ë¡œë“œ
        sample_file = genai.upload_file(path=tmp_path, display_name=uploaded_file.name)
        
        # ì²˜ë¦¬ ìƒíƒœ í™•ì¸
        while sample_file.state.name == "PROCESSING":
            time.sleep(2)
            sample_file = genai.get_file(sample_file.name)
        
        if sample_file.state.name == "FAILED":
            st.error("íŒŒì¼ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            os.remove(tmp_path)
            return None
            
    # ë¡œì»¬ ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(tmp_path)
    return sample_file

# íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆê±°ë‚˜ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì²˜ë¦¬
if uploaded_file and (st.session_state.last_uploaded_filename != uploaded_file.name):
    st.session_state.gemini_file = process_file(uploaded_file)
    st.session_state.last_uploaded_filename = uploaded_file.name
    st.session_state.chat_history = [] # ìƒˆ íŒŒì¼ì´ë©´ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    st.session_state.summary = None # ìƒˆ íŒŒì¼ì´ë©´ ìš”ì•½ ì´ˆê¸°í™”

# íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆì„ ë•Œ í‘œì‹œë˜ëŠ” UI
if st.session_state.gemini_file:
    # íƒ­ ìƒì„± (ìš”ì•½ vs ì±„íŒ…)
    tab1, tab2 = st.tabs(["ğŸ“‘ ìš”ì•½ ë³´ê¸°", "ğŸ’¬ ë¬¸ì„œì™€ ëŒ€í™”í•˜ê¸°"])

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = genai.GenerativeModel('gemini-3-flash-preview')

    with tab1:
        if st.session_state.summary:
            st.markdown(st.session_state.summary)
        else:
            if st.button("ğŸ“ ì´ ë¬¸ì„œ ìš”ì•½í•˜ê¸°", type="primary"):
                with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                    try:
                        response = model.generate_content([st.session_state.gemini_file, "ì´ ë¬¸ì„œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”."])
                        st.session_state.summary = response.text
                        st.markdown(response.text)
                    except Exception as e:
                        st.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    with tab2:
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.chat_history.append({"role": "user", "content": prompt})

            # ëª¨ë¸ ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # ëŒ€í™” ë§¥ë½ êµ¬ì„± (ë©€í‹°ëª¨ë‹¬)
                        # ë‹¨ìˆœí•œ ë°©ì‹: ë§¤ë²ˆ íŒŒì¼ê³¼ ì§ˆë¬¸ì„ í•¨ê»˜ ë˜ì§€ê±°ë‚˜, ChatSession ì‚¬ìš©
                        # ì—¬ê¸°ì„œëŠ” ChatSessionì„ ì‚¬ìš©í•˜ë˜ history ê´€ë¦¬ë¥¼ ì§ì ‘ ì œì–´
                        
                        # íˆìŠ¤í† ë¦¬ í¬ë§· ë³€í™˜ (Gemini SDK í˜•ì‹)
                        history_for_gemini = []
                        # ì²« ë©”ì‹œì§€ì— íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—­í• )
                        history_for_gemini.append({
                            "role": "user",
                            "parts": [st.session_state.gemini_file, "ì´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ê²ƒì…ë‹ˆë‹¤."]
                        })
                        history_for_gemini.append({
                            "role": "model",
                            "parts": ["ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ë¬¸ì„œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."]
                        })

                        # ì´ì „ ëŒ€í™” ë‚´ìš© ì¶”ê°€
                        for msg in st.session_state.chat_history[:-1]: # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì œì™¸
                            role = "user" if msg["role"] == "user" else "model"
                            history_for_gemini.append({
                                "role": role,
                                "parts": [msg["content"]]
                            })
                        
                        # ì±„íŒ… ì„¸ì…˜ ì‹œì‘ ë° ë©”ì‹œì§€ ì „ì†¡
                        chat = model.start_chat(history=history_for_gemini)
                        response = chat.send_message(prompt)
                        
                        st.markdown(response.text)
                        
                        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
                        st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                        
                    except Exception as e:
                        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

else:
    # íŒŒì¼ì´ ì—†ì„ ë•Œ ì´ˆê¸° í™”ë©´
    st.markdown("""
    ### ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!
    
    ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **PDF ë¬¸ì„œ**ë¥¼ ì—…ë¡œë“œí•˜ë©´:
    1. ë¬¸ì„œì˜ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ **ìš”ì•½**í•´ ì¤ë‹ˆë‹¤.
    2. ì±—ë´‡ê³¼ ëŒ€í™”í•˜ë©° ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ **ì§ˆì˜ì‘ë‹µ**ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•´ ë³´ì„¸ìš”! ğŸš€
    """)
